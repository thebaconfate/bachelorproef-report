\documentclass[a4paper]{article}

% Load the VUB package.
% This has many options, please read the documentation at
% https://gitlab.com/rubdos/texlive-vub
\usepackage{vub}
\usepackage[english]{babel}

% Some highly suggested packages, please read their manuals.
\usepackage{hyperref}
\usepackage{float}
\usepackage{cleveref}
\usepackage[natbib, style=ieee]{biblatex}
\usepackage{csquotes}
\addbibresource{bibliography.bib}
\setlength\parskip{\baselineskip}

\title{Delivering systems with Stork}
\pretitle{\flushleft{Bachelor thesis submitted in partial fulfillment of the requirements for the degree of bachelor of science: Computer Science}}
\subtitle{ A distributed computing deployment tool}
\author{GÃ©rard Lichtert}
\date{\today}
\promotors{Promotors: Prof.\ Dr.\ Joeri de Koster and Prof.\ Dr.\ Wolfgang de Meuter. \and Advisor: Mathijs Saey}
\faculty{Sciences and Bio-Engineering sciences}

\begin{document}
\maketitle
\tableofcontents
\newpage
\raggedright{}


\section{Introduction}
In a world of electronics and machines where power consumption is always increasing, optimizing power consumption is becoming increasingly important. While electricity is expensive, the main reason lies in climate change. This is because the majority of our electricity production still comes from non-renewable sources, such as coal, oil, and gas \cite{owid-energy-mix}. These sources produce a lot of CO\textsuperscript{2}, and other greenhouse gases, which are the main contributors to climate change. While there is research being done to optimize energy generation, optimizing power consumption is becoming increasingly important. This means that we as programmers can also play a role in optimizing our programs to consume less energy.

In the world of computing, cloud computing is responsible for 1\% of the worldwide energy consumption \cite{cloudcomputingenergycrisis}. To make use of the cloud, we do not only need electricity to power the devices that provide cloud computing but also electricity to power the Internet, which also plays a significant role in energy consumption. This is because the Internet is the backbone of most if not all, communication between devices and applications. The amount of connected devices and applications keeps growing, which leads to higher network usage. Consequently, higher network usage also leads to higher energy consumption, which leads to a higher carbon footprint \cite{RATHEESH}. Higher network usage also requires better infrastructure to handle the increased data volume, which in turn also requires more energy \cite{datavolumeeffects}. To reduce the network load we need to look at the data that is being sent through the network and if we can reduce it.

Data is usually transported through the network for a few reasons. Sometimes it is to send data to a device to update local data, like a chat message that needs to be added to the chat, or a new email that needs to be downloaded. While often compressed, the data is used as-is, and thus cannot be further reduced. Other times, however, data is sent to be processed. This can potentially be optimized by applying the edge-computing principle. This means that (part of) the data that is originally meant for processing is processed locally first, potentially reducing the amount of data that needs to be sent after preprocessing it. Logically, the network load, and consequently the energy consumption, should be reduced. However, for a certain set of devices or applications, it could be optimal to pre-process the complete set of data prior to sending it over the network, while for another set of devices or applications, it could be optimal to send the data directly to the server. Sometimes, however, the optimal configuration could be a combination of the two. This gives rise to the question of how we can declare how certain data is processed, and where it is processed and on top of that change the where without much manual intervention. Moreover, we want this to be available in Python because it could be interesting for further data science\cite{datasciencelanguage} or AI applications, in which the language is known to be very popular. For this purpose, we introduce Stork.

Stork is a distributed computing deployment tool, written in Python that makes it possible to deploy distributed systems in a declarative way. It allows us to change the deployment configuration as well as declare where which data gets processed. It does so by delivering the correct parts of the program to the correct devices. Hence, the name Stork.

We will know that the tool is successful if we can use the tool as a library to deploy a distributed system without manual intervention. Furthermore, the tool should allow us to change the configuration of the deployment, and declare where which data gets processed. Lastly the data must correctly be processed on the declared devices.
\section{Background}
To start building Stork we need to look at the goals that our tool should achieve. As mentioned in the introduction, we require a tool that allows us to declare where which data gets processed. This means that we need to be able to deploy parts of our program to different devices. Consequently, this means that our tool needs to work in the context of distributed systems. For this we need to choose a distributed computing paradigm that allows us to deploy our system in a distributed way, as well as change where parts of our programs reside.
Next, we need to choose a programming language of implementation, while keeping several factors in mind, such as, popularity, the use case of the programming language and the available libraries or technologies that exist in the language for our chosen paradigm.
After choosing our programming language, we need to look at the available technologies and libraries in the programming language and choose the one(s) that best fit our needs. It could happen that we need other libraries or technologies to support the ones we choose but, we will cross that bridge when we get there.
\subsection{Distributed computing paradigm}
To start with distributed computing, we have to look for a suitable distributed computing paradigm that allows our system to be deployed from the cloud without much manual intervention, yet is able to do what we require it to do. There are several options, such as:
\begin{enumerate}
    \item Message Passing Interface (MPI)\cite{MPI}
    \item Remote Procedure Call (RPC)\cite{RPC}
    \item Shared Memory Model\cite{SMM}
    \item The Actor Model as described in \cite{ActorModel}
    \item Publish/Subscribe (Pub/Sub) as described in \cite{PubSub}
\end{enumerate}
While each paradigm has their strengths and drawbacks, we will be using the Actor Model. Primarily because its modularity. Each actor encapsulates its state and behavior, which makes it a prime candidate to encapsulate the behavior of the parts that process certain parts of data. This allows us to easily move part of the data processing pipeline from one device to another. Which helps with our goal of declaring where which data gets processed. Interestingly, it can also encapsulate the behavior of IoT devices, which according to \cite{differentnetworkneedsiot} will account for 50\% of all networked devices by 2023. Seeing as IoT devices are becoming increasingly important, they should be a factor in our choice of distributed computing paradigm.

While it is technically possible to achieve modularity in MPI, RPC, and the Shared Memory Model, due to the tight coupling of those models, it is harder to achieve. This is because the state and behavior of the system are not encapsulated in a single entity, but rather spread across the entire system. This makes it harder to move parts of the system around. The Pub/Sub model is also a good candidate, however, it is more suited for event-driven systems, rather than systems with direct communication.

Other than the modularity, we also choose it for its maintainability. Since each part of the system is encapsulated in an Actor, we can easily change the behavior of parts of the system, instead of having to change our entire system. Another reason is scalability. We are able to distribute actors across different systems and machines. Which makes it perfect for moving parts of the data processing. Fault-tolerance makes it easier to contain errors and within individual actors and not propagate this to the entire system. The asynchronous nature of the Actor Model allows us to sparely use resources as needed, which will presumably reduce the required energy of the system, helping with the energy optimization. Lastly, through the message-based communication between Actors, we can easily decouple components, which in turn makes it easier to debug and test our systems. This is beneficial because distributed systems can quickly become very complex.
\subsection{Programming language of implementation}
The next step is to choose a programming language that supports the Actor Model. However, before listing the programming languages that support the Actor model, we need to consider a few things first. We want our tool to be maintainable. This means that choosing a programming language that is popular and has a large community is important. Furthermore, when processing data, companies tend to analyze the data, and perform data science on it. This means that ideally we should choose a programming language that is also used in data science, so that users of Stork can stay in the same language. Lastly but more importantly, we should choose a programming language that has libraries or technologies that support the Actor Model. This is important because otherwise we have to make our own implementation of the Actor Model, which is not ideal, considering there are already several implementations available.

A quick google search yields the following programming languages that support the Actor Model:
\begin{enumerate}
    \item Scala with its Akka library
    \item Java with its Akka library
    \item Erlang, where the Actor Model is built into the language
    \item Elixir, where the Actor model is built into the language, and based on Erlang, Open telecom platform (OTP)
    \item JavaScript with its js.Actor library
    \item Python with its Pykka and Thespianpy libraries
    \item C\# with its Akka.NET library
    \item Rust with its Actix library
\end{enumerate}

In terms of popularity, according to \cite{stackoverflowsurvey}, they are ranked as follows\footnote{TypeScript is emitted since it uses JavaScript libraries}:
\begin{enumerate}
    \item JavaScript
    \item Python
    \item Java
    \item C\#
    \item Rust
    \item Scala
    \item Elixir
    \item Erlang
\end{enumerate}
With the last three being used by less than \(5\%\) of the respondents, and the top two being used by roughly \(49\%-63\%\) of respondents, we can focus on the top two. To stay in the same programming language that is often used by data scientists, we choose Python. This because according to, Python is the most popular language for data science, and while JavaScript is also used for data science, it does not offer nearly as much data science libraries as Python does.
\subsection{Technologies and libraries}
As mentioned when choosing the programming language of implementation, Python offers two Actor Model libraries. Pykka and Thespianpy. Setting Pykka and thespian next to each other and comparing them yields the following results:
\subsubsection{Pykka}
Quoting the documentation of the library: \enquote{Pykka is a Python implementation of the actor model. The actor model introduces some simple rules to control the sharing of state and cooperation between execution units, which makes it easier to build concurrent applications.} However, reading further down in the documentation we see that Pykka has some shortcomings, as it does not support linking actors, supervisors, or supervisor groups. It does not support communicating with actors running on other hosts, nor does it come with a set of predefined message routers. This would mean that we have to implement this ourselves, particularly the communication between actors running on other hosts. This is important because we are building a distributed system after all, and we need to be able to communicate between different hosts. Notably it does have \(\approx 1200\) stars on Github, which comparing it to Thespianpy, is more. Meaning that it is more popular than Thespianpy and thus has a larger community using it.
\subsubsection{Thespianpy}
The documentation states that: \enquote{Thespian is a Python library providing a framework for developing concurrent, distributed, fault-tolerant applications. It is built on the Actor Model which allows applications to be written as a group of independently executing but cooperating "Actors" which communicate via messages. These Actors run within the Actor System provided by the Thespian library.} More importantly, Thespianpy allows us to run Thespian on different hosts, while internally handling the messaging between actors, providing an out-of-the-box solution for Actor communication between different hosts. This means that when using the Thespian library, we do not have to implement the communication between actors running on different hosts. It also means that we can user the built-in communication to declare where which data gets processed. However, it only has \(\approx300\), which is significantly less than Pykka.
\subsubsection{Our verdict}
While Pykka is more popular than Thespianpy, it does not support communication between actors running on different hosts. As this is a crucial feature for distributed computing, we choose Thespianpy.
\section{A deep dive into Thespianpy}
Now that we have chosen the technologies and libraries that we will be using to build Stork, we first need to design the tool to see if we need anything else. Since this tool will be built using Thespian, we will heavily rely on its provided features. This gives rise to a few questions:
\begin{enumerate}
    \item How do we deploy the system using Thespianpy?
    \item How can we declare where which data gets processed, using Thespianpy?
\end{enumerate}
Looking at the Thespianpy documentation, it states that we can deploy a system by starting an Actorsystem on a device. This Actorsystem will then manage the local Actors and their communication for us. Consequently, this also means that we will have to spin up an Actorsystem on each device, if we want Actors to live on those devices. Perhaps worth mentioning is that Thespianpy Actorsystems have different communication protocols, from which we can choose. However, the recommended setting for distributed systems is to use 'multiprocTCPBase', which lets Actors run on their own separate process, creating a truly asynchronous system. This also means that the communication method between Actors is TCP. Another option is to user 'multiprocUDPBase', which uses UDP as the communication method. Consequently, there will be no guarantee that the messages will be delivered, as this is a characteristic of UDP. The other options, multiprocQueueBase and simpleSystembase do not support multiple systems and cannot be used for inter-system communications, respectively. The configuration that will be used for Stork is 'multiprocTCPBase'. Prior to continuing the deployment of the Actorsystems across several devices, we need to introduce some important concepts regarding the Actors, Capabilities and Conventions.

As asked before, how can we declare where which data gets processed in our distributed system, using Thespianpy? As mentioned in section 2.1, where the distributed computing paradigm was chosen, we can leverage the modularity of the Actor Model to split our data processing pipeline in small enough segments. Ideally each segment would be responsible for processing one part of the data, obtaining more flexibility for moving parts around. More concretely, each segment in our pipeline would be encapsulated by an Actor, making each Actor responsible for processing a part of the data. This is how we declare which data gets processed, but how do we declare where our data gets processed?

Logically, this would mean that the Actor processing a specific part of the data should be placed on the device where we want that part of the data processed. While thespianpy does support the creation of Actors on remote hosts and their communication, it is not evident as to how the same Actor is supposed to be spawned on different hosts. Let me explain: Thespian has a built-in mechanism to allow Actors to be spawned on a remote host however, this is not by declaring the Actor to be spawned on said host. Instead, Thespianpy allows for restricting an Actor to be spawned on certain hosts, without the guarantee that the Actor is spawned on the host that we want the Actor to be spawned on. This built-in mechanism is called 'Capabilities', which allows an Actorsystem to be spun up with certain capabilities, and an Actor to be spawned only on the Actorsystem where those capabilities are present. Furthermore, Thespianpy will always spawn an Actor on the first Actorsystem within the distributed system that has the required capabilities. Consequently, this does not guarantee that we can spawn the same Actor on different devices, as more often than not, Thespianpy will spawn the same Actor multiple times on the same Actorsystem. This follows from the fact that the same Actorsystem will often be the first one where the Actor is able to spawn. This is a problem, because in a scenario where we have several sensors, and we want to spawn an Actor on all the sensors, we won't be able to guarantee that the Actor is spawned on all the sensors.

Worth mentioning is that Thespianpy allows for Actor creation by invoking a method on the local Actorsystem. However this only works when the capabilities that the Actor requires to be spawned on the local Actorsystem are present on the local Actorsystem. If they are not, the program crashes. So how are we supposed to spawn an Actor on a remote device? Well while we cannot spawn an Actor on a remote machine using the Actorsystem, we can using an Actor. This means we would first have to create an Actor locally and use that Actor to spawn an Actor with incompatible capabilities with that of the local Actorsystem, to spawn it remotely.

At a first glance, Thespianpy seemed to have a method, that when called from an Actor, to spawn another Actor, we could pass the capabilites that the Actorsystem is required to have to be able to spawn the Actor. Say we have a distributed system with three devices, A, B, and C. We want to spawn an Actor that pre-processes data on devices B and C. We could let the Actorsystems on those devices have a common capability, say 'device\_B\_C'. Now in theory, if we give each Actorsystem its host name as a capability as well, we should be able to guarantee that the Actor is spawned on devices B and C if we pass the 'device\_B\_C' capability as well as the hostname of the remote device where the Actor should be spawned. However, this is not the case. When testing this method, while Thespianpy would interpret the common capability correctly, it ignored the hostname capability. Meaning that we still did not have the guarantee that the Actor would spawn on both B and C and not twice on either device. Presumably, the Capabilities are not processed in a way that the Actorsystem is required to have all declared Capabilities but rather only one of them.

Making another attempt at solving the problem distribution of Actors, let us try to exploit how Actorsystems are connected with each other. Actorsystems work by registering themselves to a convention leader. Meaning that an Actorsystem or rather the leader Actorsystem has to be spun op before the rest of the Actorsystems within the convention. While it works mostly internally and is hidden from the programmer, we can still get be informed of the Actorsystems registering to the convention leader. This is achieved by creating an Actor on the leader Actorsystem and invoking \textit{self.notifyOnSystemRegistrationChanges}. This method will tell the leader Actorsystem that the Actor subscribes itself to receive notifications about updates in the convention. It provides the Actor with notifications of registrations and de-registrations, as well as the admin address of the remote Actorsystem as well as the capabilities of the remote Actorsystem. Note that the admin address of the remote Actorsystem is actually the address (or reference) to a top-level Actor of the remote Actorsystem, that manages the Actorsystem internally, not the the address or reference to the Actorsystem itself. This Actor is invisible to the user.

When working locally with Actors, and creating other Actors, we actually create references, or addresses of those Actors, with which we can asynchronously send messages to. Knowing this, theoretically it could be possible to use the provided admin address of the remote Actorsystem to create Actors on the remote Actorsystem. We could do this by sending it a message to spawn an Actor. However, that is not the case. This because if we wanted the remote Actor to be able to spawn Actors, we would first have to implement a method in that Actor that would allow the Actor to interpret the sent message that tells it to spawn an Actor and send the created reference back. Since the remote Actor is invisible to the user, we cannot implement this method, leaving us with a way to send messages to the remote Actor but no way to for it to interpet it. We are yet again left with no solution. However, not all is in vain because we can still use the capabilities to our advantage to denote certain properties of the device on which the Actorsystem resides. We can keep track of the devices that have certain capabilities and then use this information to know where to spawn the Actors. However, this is not yet a complete solution.

What if instead of trying to get references to the remote Actorsystems to the leader Actorsystem, we get the reference of an Actor which resides in the leader Actorsystem to the remote Actorsystem? After all, we do know that with the Capabilities feature, we can restrict an Actor to be spawned on an Actorsystem. More concretely, we can force a remote Actorsystem to spawn an Actor locally, that spawns an Actor that can only be spawned in the leader Actorsystem. This way we can get a reference to the leader Actorsystem, and communicate to that Actor the reference of the Actor to further interact with it as needed. For example for spawning other Actors. Will this work? Not always sadly. While Thespianpy's documentation states that when we spawn an Actor multiple times on the same system it will try to reuse the same Actor, this is not always the case. Meaning that if we create an administrative Actor on the convention leader to be notified about remote systems, and force remote systems to spawn the same adminstrative Actor (which will then be spawned on the convention leader because of its capability restriction) it won't always reference the initially created administrative Actor. Luckily for us there is a way to force Thespianpy to reuse the same Actor. This is done by using a global name for the Actor. This way, when an Actorsystem tries to spawn the administrative Actor, it will first look for a global reference to it. Only if it is not found, does it create a new one. This way we can guarantee that the same administrative Actor is referenced by all remote systems.

What does this mean for Stork? It means that there are some implications when deploying Actorsystems, as we firstly need to spin up an Actorsystem on the convention leader, as well as create the administrative Actor, which should have a global name, as well as be registered to get notifications about convention updates. Furthermore, we need to spin up Actorsystems on the other devices, that create a local Actor that tries to create the administrative Actor, but instead get a reference to the already existing one on the convention leader, while registering themselves as a reference to the convention leader. This reference can later be used for spawning other Actors on the remote devices. With the help of the administrative Actor, that keeps track of the capabilities of remote Actorsystems, it can spawn Actors on the remote Actorsystems by sending a message that invokes a method to spawn the declared Actor. This way we can, for example tell the administrative Actor to spawn an Actor on all remote Actorsystems with the capability "Sensor", which would spawn an Actor on all devices that have the capability "Sensor".

This implies that Stork requires two programs. One to deploy the Actorsystem on the convention leader as well as spawn the administrative Actor, and one to deploy the Actorsystems on the other remote devices, as well as spawn their respective registrator Actors. However, to run these programs we need to create a connection with the remote devices and run these programs. This can be done by using SSH, which is a secure way to connect to the remote devices. While it probably is not an issue to do this in small distributed systems, manually SSH'ing to 30 different devices in a large distributed system is not ideal. This means that we require something to automate this process.

\section{Automating the deployment}
When automating deployments, Infrastructure as Code (IaC) is often a topic that comes up, as it allows us to automate the process of deploying infrastructure. For IaC we have several options, as we can use several tools and libraries to automate the deployment. Some of the most popular tools are:
\begin{enumerate}
    \item Ansible
    \item Chef
    \item Puppet
    \item SaltStack
    \item Terraform
    \item CFEngine
    \item Fabric
\end{enumerate}
\printbibliography
\end{document}
