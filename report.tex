\documentclass[a4paper]{article}

% Load the VUB package.
% This has many options, please read the documentation at
% https://gitlab.com/rubdos/texlive-vub
\usepackage{vub}
\usepackage[english]{babel}

% Some highly suggested packages, please read their manuals.
\usepackage{hyperref}
\usepackage{float}
\usepackage{cleveref}
\usepackage[natbib,style=apa]{biblatex}
\usepackage{csquotes}
\addbibresource{bibliography.bib}
\setlength\parskip{\baselineskip}

\title{Delivering systems with Stork}
\pretitle{\flushleft{Bachelor thesis submitted in partial fulfillment of the requirements for the degree of bachelor of science: Computer Science}}
\subtitle{ A distributed computing deployment tool}
\author{GÃ©rard Lichtert}
\date{\today}
\promotors{Promotors: Prof.\ Dr.\ Joeri de Koster and Prof.\ Dr.\ Wolfgang de Meuter. \and Advisor: Mathijs Saey}
\faculty{Sciences and bioengineering sciences}

\begin{document}
\maketitle
\tableofcontents
\newpage
\raggedright{}


\section{Introduction}
In a world of electronics and machines where power consumption is always increasing, optimizing power consumption is becoming increasingly important. While electricity is expensive, the main reason lies in climate change. According to \cite{owid-energy-mix}, the majority of our electricity production still comes from non-renewable sources, such as coal, oil, and gas. These sources produce a lot of CO\textsuperscript{2}, and other greenhouse gases, which are the main contributors to climate change. While there is research being done to optimize energy generation, optimizing power consumption is becoming increasingly important. This means that we as programmers can also play a role in optimizing our programs to consume less energy. In the world of computing, according to \cite{cloudcomputingenergycrisis} cloud computing takes 1\% of worldwide energy consumption. While this may not seem like much, it is still a significant amount of energy.

Computing like most electronics, require electricity to function, however when computers communicate with each other they also have to send data, or make requests through the Internet. This leads to a very high network usage, since in today's world, we are unequivocally connected with each other. Furthermore, the amount of devices using the internet keeps growing, which leads to even more network usage. Higher network usage also leads to higher energy consumption, which leads to a higher carbon footprint, as stated in \cite{RATHEESH}. \cite{datavolumeeffects} states that there is also an increase in energy consumption due to the infrastructure required for the increase in data volume. To reduce the network load we need to look at the data that is being sent through the network and if we can reduce it.

Data is usually transported through the network for a few reasons. Sometimes it is to send data to a device to update local data, like a chat message that needs to be added to the chat, or a new email that needs to be downloaded. While often compressed, the data is used as-is, and thus cannot be further reduced. Other times, however, data is sent to be processed. This can potentially be optimized by applying the edge-computing principle. This means that (part of) the data that is originally meant for processing is processed locally first, potentially reducing the amount of data that needs to be sent after preprocessing it. Logically, if the data is smaller after preprocessing, the network load should be reduced, and consequently the energy consumption. However, for a certain set of devices it could be optimal to pre-process the complete set of data prior to sending it over the network. While for another set of devices it could be optimal to send the data directly to the server. Sometimes the optimal configuration could be a combination of the two. This gives rise to the question of how we can easily declare where which data gets processed.

In this thesis we introduce a tool for this purpose: Stork. Stork is a distributed computing deployment tool that makes it possible to deploy distributed systems in a declarative way. It allows us to change the deployment configuration as well as declare where which data gets processed. It does so by delivering the correct parts of the program to the correct devices. Hence, the name Stork.

We will know that the tool is successful if we can use the tool as a library to deploy a distributed system without manual intervention. Furthermore, the tool should allow us to change the configuration of the deployment, and declare where which data gets processed. Lastly the data must correctly be processed on the declared devices.
\section{Background}
To start building Stork we need to look at the goals that our tool should achieve. As mentioned in the introduction, we require a tool that allows us to declare where which data gets processed. This means that we need to be able to deploy parts of our program to different devices. Consequently, this means that our tool needs to work in the context of distributed systems. For this we need to choose a distributed computing paradigm that allows us to deploy our system in a distributed way, as well as change where parts of our programs reside.
Next, we need to choose a programming language of implementation, while keeping several factors in mind, such as, popularity, the use case of the programming language and the available libraries or technologies that exist in the language for our chosen paradigm.
After choosing our programming language, we need to look at the available technologies and libraries in the programming language and choose the one(s) that best fit our needs. It could happen that we need other libraries or technologies to support the ones we choose but, we will cross that bridge when we get there.
\subsection{Distributed computing paradigm}
To start with distributed computing, we have to look for a suitable distributed computing paradigm that allows our system to be deployed from the cloud without much manual intervention, yet is able to do what we require it to do. There are several options, such as:
\begin{enumerate}
    \item Message Passing Interface (MPI) as described in \cite{MPI}
    \item Remote Procedure Call (RPC) as described in \cite{RPC}
    \item Shared Memory Model as described in \cite{SMM}
    \item The Actor Model as described in \cite{ActorModel}
    \item Publish/Subscribe (Pub/Sub) as described in \cite{pubsubmodel}
\end{enumerate}
While each paradigm has their strengths and drawbacks, we will be using the Actor Model. Primarily because its modularity. Each actor encapsulates its state and behavior, which makes it a prime candidate to encapsulate the behavior of the parts that process certain parts of data. This allows us to easily move part of the data processing pipeline from one device to another. Which helps with our goal of declaring where which data gets processed. Interestingly, it can also encapsulate the behavior of IoT devices, which according to \cite{differentnetworkneedsiot} will account for 50\% of all networked devices by 2023. Seeing as IoT devices are becoming increasingly important, they should be a factor in our choice of distributed computing paradigm.

While it is technically possible to achieve modularity in MPI, RPC, and the Shared Memory Model, due to the tight coupling of those models, it is harder to achieve. This is because the state and behavior of the system are not encapsulated in a single entity, but rather spread across the entire system. This makes it harder to move parts of the system around. The Pub/Sub model is also a good candidate, however, it is more suited for event-driven systems, rather than systems with direct communication.

Other than the modularity, we also choose it for its maintainability. Since each part of the system is encapsulated in an Actor, we can easily change the behavior of parts of the system, instead of having to change our entire system. Another reason is scalability. We are able to distribute actors across different systems and machines. Which makes it perfect for moving parts of the data processing. Fault-tolerance makes it easier to contain errors and within individual actors and not propagate this to the entire system. The asynchronous nature of the Actor Model allows us to sparely use resources as needed, which will presumably reduce the required energy of the system, helping with the energy optimization. Lastly, through the message-based communication between Actors, we can easily decouple components, which in turn makes it easier to debug and test our systems. This is beneficial because distributed systems can quickly become very complex.
\subsection{Programming language of implementation}
The next step is to choose a programming language that supports the Actor Model. There are several programming languages that support the Actor Model, such as:



\printbibliography
\end{document}
