\documentclass[a4paper]{article}

% Load the VUB package.
% This has many options, please read the documentation at
% https://gitlab.com/rubdos/texlive-vub
\usepackage{vub}
\usepackage[english]{babel}

% Some highly suggested packages, please read their manuals.
\usepackage{hyperref}
\usepackage{float}
\usepackage{cleveref}
\usepackage[natbib,style=apa]{biblatex}
\usepackage{csquotes}
\addbibresource{bibliography.bib}
\setlength\parskip{\baselineskip}

\title{Delivering systems with Stork}
\pretitle{\flushleft{Bachelor thesis submitted in partial fulfillment of the requirements for the degree of bachelor of science: Computer Science}}
\subtitle{ A distributed computing deployment tool}
\author{GÃ©rard Lichtert}
\date{\today}
\promotors{Promotors: Prof.\ Dr.\ Joeri de Koster and Prof.\ Dr.\ Wolfgang de Meuter. \and Advisor: Mathijs Saey}
\faculty{Sciences and bioengineering sciences}

\begin{document}
\maketitle
\tableofcontents
\newpage
\raggedright{}


\section{Introduction}
In a world of electronics and machines where power consumption is always increasing, optimizing power consumption is becoming increasingly important. While electricity is expensive, the main reason lies in climate change. According to \cite{owid-energy-mix}, the majority of our electricity production still comes from non-renewable sources, such as coal, oil, and gas. These sources produce a lot of CO\textsuperscript{2}, and other greenhouse gases, which are the main contributors to climate change. While there is research being done to optimize energy generation, optimizing power consumption is becoming increasingly important. This means that we as programmers can also play a role in optimizing our programs to consume less energy. In the world of computing, according to \cite{cloudcomputingenergycrisis} cloud computing takes 1\% of worldwide energy consumption. While this may not seem like much, it is still a significant amount of energy.

Computing like most electronics, require electricity to function, however when computers communicate with each other they also have to send data, or make requests through the Internet. This leads to a very high network usage, since in today's world, we are unequivocally connected with each other. Furthermore, the amount of devices using the internet keeps growing, which leads to even more network usage. Higher network usage also leads to higher energy consumption, which leads to a higher carbon footprint, as stated in \cite{RATHEESH}. \cite{datavolumeeffects} states that there is also an increase in energy consumption due to the infrastructure required for the increase in data volume. To reduce the network load we need to look at the data that is being sent through the network and if we can reduce it.

Data is usually transported through the network for a few reasons. Sometimes it is to send data to a device to update local data, like a chat message that needs to be added to the chat, or a new email that needs to be downloaded. While often compressed, the data is used as-is, and thus cannot be further reduced. Other times, however, data is sent to be processed. This can potentially be optimized by applying the edge-computing principle. This means that (part of) the data that is originally meant for processing is processed locally first, potentially reducing the amount of data that needs to be sent after preprocessing it. Logically, if the data is smaller after preprocessing, the network load should be reduced, and consequently the energy consumption. However, for a certain set of devices it could be optimal to pre-process the complete set of data prior to sending it over the network. While for another set of devices it could be optimal to send the data directly to the server. Sometimes the optimal configuration could be a combination of the two. This gives rise to the question of how we can easily declare where which data gets processed.

In this thesis we introduce a tool for this purpose: Stork. Stork is a distributed computing deployment tool that makes it possible deploy distributed systems in a declarative way. It allows us to change the deployment configuration as well as declare where which data gets processed. It does so by delivering the correct parts of the program to the correct devices. Hence, the name Stork.

We will know that the tool is successful if we can use the tool as a library to deploy a distributed system without manual intervention. Furthermore, the tool should allow us to change the configuration of the deployment, and declare where which data gets processed. Lastly the data must correctly be processed on the declared devices.
\section{Background}
\subsection{Distributed computing}
To start with distributed computing, or our IoT systems we have to look for a suitable distributed computing paradigm that allows our system to be deployed from the cloud without much manual configuration, yet is able to do what we require it to do. We have several options, such as:
\begin{enumerate}
    \item Message Passing Interface (MPI) as described in \cite{MPI}
    \item Remote Procedure Call (RPC) as described in \cite{RPC}
    \item Shared Memory Model as described in \cite{SMM}
    \item The Actor Model as described in \cite{ActorModel}
    \item Publish/Subscribe (Pub/Sub)
\end{enumerate}
While each paradigm has their strengths and drawbacks, we will be using the Actor Model. Primarily because its modularity. Each actor encapsulates its state and behavior, which makes it a prime candidate to encapsulate the behavior of our IoT devices. Furthermore, using the Actor Model we can split our data processing pipeline into segments, each segment being captured by a different Actor. This allows us to easily move part of the data processing pipeline to the IoT devices or back to the server. This satisfies one of our previously stated goals. Other than the modularity, we also choose it for its maintainability. Since each part of the system is encapsulated in an Actor, we can easily change the behavior of parts of the system, instead of having to change our entire system. Another reason is scalability. We are able to distribute actors across different systems and machines. Which makes it perfect for IoT systems. Fault-tolerance makes it easier to contain errors and within individual actors and not propagate this to the entire system. The asynchronous nature of the Actor Model allows us to sparely use resources as needed, which will presumably reduce the required energy of the system. Lastly, through the message-based communication between Actors, we can easily decouple components, which in turn makes it easier to debug and test our systems. This is beneficial because distributed systems can quickly become very complex.


\printbibliography
\end{document}
